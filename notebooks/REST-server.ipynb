{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Servidor HTTP - REST api\n",
    "*autor: André Costa (2019-03-09)* [https://www.linkedin.com/in/a-l-costa]\n",
    "\n",
    "- Implementação de um servidor HTTP básico para ofereçer uma api REST para acesso aos dados do warehouse\n",
    "- **AVISO:** ESTA IMPLEMENTAÇÃO É UMA PROVA DE CONCEITO E NÃO DEVE SER UTILIZADA EM PRODUÇÃO\n",
    "\n",
    "- **END POINTS**:\n",
    "    - /estabelecimentos/lista : retorna uma lista de todos os estabelecimentos que possuem algum evento de fluxo registrado, expondo o ID (SK) e o nome dos estabelecimentos. Retornado como *text/plain*, mas formatado como *csv*. Duas columas.\n",
    "    - /estabelecimentos/detalhes/*ID/ : retorna um único registro com informações detalhadas sobre o estabelecimento, incluindo o fluxo médio para cada dia da semana, em cada período. Retornado como *text/plain*, mas formatado como *csv*. O número de colunas é variável.\n",
    "\n",
    "*OBSERVAÇÃO:* para utilizar, execute todos os passos deste script e mantenha o kernel rodando. acesse como localhost:8008/ pelo host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "spark.sql('use geodata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_estabelecimentos(opts):\n",
    "    validConc = spark.sql('select id, nome FROM concorrente WHERE isnull(end_date) \\\n",
    "        and id in (select concorrente_id FROM fluxo group by concorrente_id)')\n",
    "    data = validConc.toPandas().to_csv(None, index=False)\n",
    "    return {\n",
    "        'status': 200,\n",
    "        'type': 'text/plain',\n",
    "        'content': data\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_day = {0: 'dom', 1: 'seg', 2: 'ter', 3: 'qua', 4: 'qui', 5: 'sex', 6: 'sab'}\n",
    "periodo = {0: 'manha', 1: 'tarde', 2: 'noite'}\n",
    "\n",
    "def name_segments(day,p):\n",
    "    return '_'.join([week_day[day], periodo[p]])\n",
    "map_name_segments = UserDefinedFunction(name_segments, StringType())\n",
    "\n",
    "def estabelecimento_details(opts):\n",
    "    try:\n",
    "        c_id = int(opts[0])\n",
    "        concProfile = spark.sql('select a.id, a.codigo, a.nome, a.endereco, a.faixa_preco, \\\n",
    "            b.nome as bairro, b.populacao, b.dens_demo FROM concorrente as a INNER join bairro as b \\\n",
    "            ON a.id={} and a.bairro_id=b.codigo and isnull(b.end_date)'.format(c_id))\n",
    "        if not concProfile.count():\n",
    "            return {\n",
    "                'status': 404,\n",
    "                'type': 'text/plain',\n",
    "                'content': u'Registro não encontrado.'\n",
    "            }\n",
    "\n",
    "        profile_data = concProfile.toPandas()\n",
    "        H1 = list(profile_data)\n",
    "        R1 = profile_data.values[0]\n",
    "        R1[2] = '\\\"{}\\\"'.format(R1[2])\n",
    "        R1[3] = '\\\"{}\\\"'.format(R1[3])\n",
    "\n",
    "        fluxo = spark.sql('select AVG(a.ocorrencias) as fluxo_medio, b.dia_semana, b.periodo \\\n",
    "            FROM fluxo as a INNER join calendario as b \\\n",
    "            ON a.calendario_id=b.id WHERE concorrente_id={} group by b.dia_semana, b.periodo \\\n",
    "            order by b.dia_semana, b.periodo'.format(c_id))\n",
    "\n",
    "        fluxo = fluxo.withColumn('seg', map_name_segments(fluxo.dia_semana, fluxo.periodo)) \\\n",
    "            .drop('dia_semana', 'periodo')\n",
    "\n",
    "        fluxo_data = fluxo.toPandas().values.transpose()\n",
    "        H2 = fluxo_data[1].ravel()\n",
    "        R2 = fluxo_data[0].ravel()\n",
    "\n",
    "        H = ','.join(np.hstack((H1, H2)))\n",
    "        R = ','.join([str(x) for x in np.hstack((R1, R2))])\n",
    "        data = '\\n'.join([H, R])\n",
    "\n",
    "        return {\n",
    "            'status': 200,\n",
    "            'type': 'text/plain',\n",
    "            'content': data\n",
    "        }\n",
    "    \n",
    "    except:\n",
    "        return {\n",
    "            'status': 500,\n",
    "            'type': 'text/plain',\n",
    "            'content': u'Não foi possível obter os detalhes do estabelecimento. \\\n",
    "                verifique sua requisição.'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "handlers = {\n",
    "    'lista': list_estabelecimentos,\n",
    "    'detalhes': estabelecimento_details\n",
    "}\n",
    "\n",
    "def handle_estabelecimentos(opts):\n",
    "    try:\n",
    "        return handlers[opts[0]](opts[1:])\n",
    "    except:\n",
    "        return {\n",
    "            'status': 500, \n",
    "            'content': u'Operação para \"estabelecimentos\" inválida. \\\n",
    "                Verifique sua requisição.', \n",
    "            'type': 'text/plain'\n",
    "        }\n",
    "\n",
    "def split_path(path):\n",
    "    path_list = [x for x in path.split('/') if x!='']\n",
    "    path_list.append('')\n",
    "    return path_list\n",
    "\n",
    "entry_handlers = {\n",
    "    'estabelecimentos': handle_estabelecimentos\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 11 22:20:34 2019 Server Starts - pyspark-server:8008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.1 - - [11/Mar/2019 22:20:58] \"GET /estabelecimentos/lista HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 11 22:21:23 2019 Server Stops - pyspark-server:8008\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from http.server import BaseHTTPRequestHandler, HTTPServer\n",
    "\n",
    "HOST_NAME = 'pyspark-server'\n",
    "PORT_NUMBER = 8008\n",
    "\n",
    "\n",
    "class MyHandler(BaseHTTPRequestHandler):\n",
    "    def do_HEAD(self):\n",
    "        self.send_response(200)\n",
    "        self.send_header('Content-type', 'text/plain')\n",
    "        self.end_headers()\n",
    "\n",
    "    def do_GET(self):\n",
    "        opts = split_path(self.path)\n",
    "        try:\n",
    "            response = entry_handlers[opts[0]](opts[1:])\n",
    "        except:\n",
    "            response = {\n",
    "                'status': 404, \n",
    "                'content': u'Requisição inválida: {}'.format(self.path),\n",
    "                'type': 'text/plain'\n",
    "            }\n",
    "        \n",
    "        self.respond(response)\n",
    "\n",
    "    def handle_http(self, status_code, content_type, content):\n",
    "        self.send_response(status_code)\n",
    "        self.send_header('Content-type', content_type)\n",
    "        self.end_headers()\n",
    "        return bytes(content, 'UTF-8')\n",
    "\n",
    "    def respond(self, response):\n",
    "        data = self.handle_http(response['status'], response['type'], response['content'])\n",
    "        self.wfile.write(data)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    server_class = HTTPServer\n",
    "    httpd = server_class((HOST_NAME, PORT_NUMBER), MyHandler)\n",
    "    print(time.asctime(), 'Server Starts - %s:%s' % (HOST_NAME, PORT_NUMBER))\n",
    "    try:\n",
    "        httpd.serve_forever()\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    httpd.server_close()\n",
    "    print(time.asctime(), 'Server Stops - %s:%s' % (HOST_NAME, PORT_NUMBER))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
